---
title: "Spotify Wrapped"
author: "Daria Koppes"
date: "28-3-2021"
output:
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: cosmo
---

```{r, echo=FALSE}
library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
library(grid)
library(gridExtra)
library(tidymodels)
library(ggdendro)
library(heatmaply)
```
```{r}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  
```

```{r, echo=FALSE}
eighteen <- get_playlist_audio_features("spotify", "37i9dQZF1EjuRTGXCnqj3q") 
nineteen <- get_playlist_audio_features("spotify", "37i9dQZF1Ethn3c8yyjsG9") 
twenty <- get_playlist_audio_features("spotify", "37i9dQZF1EM1eb9t3OIKaB")
billie <- get_playlist_audio_features("spotify", "7L8fVkNZIHQ38k0hkcJkVo")
```

```{r, echo=FALSE}
combined_1 <-
  bind_rows(
    eighteen %>% mutate(category = "Wrapped playlist 2018") %>% slice_head(n = 5),
    nineteen %>% mutate(category = "Wrapped playlist 2019") %>% slice_head(n = 5),
    twenty %>% mutate(category = "Wrapped playlist 2020") %>% slice_head(n = 5)
  )
combined <-
  bind_rows(
    eighteen %>% mutate(category = "Wrapped playlist 2018"),
    nineteen %>% mutate(category = "Wrapped playlist 2019"),
    twenty %>% mutate(category = "Wrapped playlist 2020")
  )

billie <-
  bind_rows(
        nineteen %>% mutate(category = "Wrapped playlist 2019"),
    billie %>% mutate(category = "Billie Eilish")
  )

```

```{r}
combined_features <-
  combined_1 %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    category = factor(category),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

```{r}
combined_recipe <-
  recipe(
    category ~
      loudness +
      duration +
      energy + 
      c02 + c03 + c04 + c11,
    data = combined_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].
```

```{r}
combined_cv <- combined_features %>% vfold_cv(10)
```

```{r}
knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
combined_knn <- 
  workflow() %>% 
  add_recipe(combined_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    combined_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r, echo=FALSE, results='hide', fig.show='hide'}
combined_knn %>% get_pr()
```


### **Introduction** of the chosen corpus

**Research points**

The corpus consists of three of my own wrapped Spotify playlists, from the years 2018, 2019 and 2020. I chose this corpus because I want to find out how the type of music I listened too has evolved over the last three years. The type of music will be defined according to different Spotify features such as *Energy*, *Tempo*, *Timbre* and more. Another research point is to find out if it is possible looking at the kind of music I was listening to, to decide the general mood of that year for me. 2019 for example was a general nice year for me with a lot of traveling and fun things planned, 2020 on the other hand was a more hard year, like for most people. Is this reflected in the music of my wrapped spotify playlists? 


**Expectations**

Comparison points for the wrapped playlists will be different Spotify features that are available on the playlist level. For the mood of songs features of the songs like valence and energy will be looked at in more depth. I expect that 2020 will have more 'sad' songs because my mood was more sadder in this year compared to 2019 and 2018. I expect 2019 to have the opposite result and contain more 'happy' and high energy, high tempo songs. For 2018 I have no specific expectations, my memory of that year is not very distinct and I did not listen to spotify that much yet in 2018 (I did not have a premium account yet). I do expect for 2018 and 2019 to have more foreign music in them than 2020. I tend to be listening to more foreign music while traveling, so I expect 2018 and 2019 to have more Spanish/Portuguese/French artists in them than 2020 for example. I am unsure if my type of music has significantly changed over the past three years, or stayed the same but I am curious find it out. 


**Strengths and limitations of the corpus**

The strength of the corpus is that it contains a significant amount of representative songs and especially for 2019 and 2020 I recognize all the numbers in it. In 2019 I was also pretty obsessed with Billie Eilish so it is typical to see that 20 of the 100 songs in my wrapped playlist are by her. For 2018 however I notice that some songs in the wrapped playlist I have never listened to before. I do not know how they got in my wrapped playlist. For example: Pastempomat sang by Dawid Pdsiadlo is a polish song and I am certain that I never listened to this song or any other polish song before. I will keep these songs in the playlist to have the same number of songs in every playlist, but remember that there are some songs in the 2018 wrapped playlist that are not representable for me. 

![Wrapped playlist 2018](images/2018.png){width=33%}    ![Wrapped playlist 2019](images/2019.png){width=33%}    ![Wrapped playlist 2020](images/2020.png){width=33%}


### Lets start by comparing the **energy** of the songs

```{r, fig.align='center', fig.width=8}
histogram <- combined %>%
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1, col="black", fill = "#0088cc") +
  facet_wrap(~category) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme_light() +
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  theme( 
  axis.text = element_text(size = rel(0.95)), 
  strip.background = element_rect(fill="#008ae6", size=1.5, linetype="solid"),
  strip.text = element_text(size = 12),
  plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
) +
    labs(                      
    x = "Energy",
    y = "Number of songs",
    colour = element_blank()
  ) +
    ggtitle("The energy of songs over the years") 


density <- ggplot(combined, aes(x=energy, fill = category)) +
  geom_density(alpha = 0.4) +
    scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme_light() +
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
      labs(                      
    x = "Energy",
    y = "Density",
    fill = element_blank()
  ) +
  theme(
    plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  )+
    ggtitle("The density of songs filtered by energy over the years") 

grid.arrange(histogram, density, nrow=2)
```


***

To start looking at the differences in music throughout the year and focussing on the mood of the songs I started with a histogram comparing the energy of the songs over the three years. 

To my surprise the year 2019 is actually the year with the lowest amount of high energy songs. As I mentioned in the introduction 2019 was a good year for me and I was wondering if that would show in the type of music. Maybe because it was a good year I did not need high energy music to cheer me up but could listen to more low-energy songs and that could explain the density being lower in 2019 for high energy songs in comparison to 2020 and 2018. 

Another explanation could lie in the fact that 2019 contains a large amount of Billie Eilish songs. To see the more in depth influence of Billie Eilish see the storyboard: In depth visualisation of the influence of **Billie Eilish**. 


### Adding Valence to Energy to get the mood of the song: How much is my music of 2018, 2019 and 2020 alike in **mood**? 

```{r, fig.align='center', fig.width=9}
scatterplotyears <- combined %>%
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
    )
  ) +
  geom_point(color = '#008ae6', alpha = 0.6, size=2) +
  facet_grid(.~category) +     # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Valence",
    y = "Energy",
    colour = element_blank()
  ) +
  theme( 
  axis.text = element_text(size = rel(0.95)), 
  strip.background = element_rect(fill="#008ae6", size=1.5, linetype="solid"),
  strip.text = element_text(size = 12),
  plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5), 
  legend.key = element_rect(fill = "#e7e7e4"),
) + 
  annotate("text", x = 0.1, y = 0.05, 
           label = "Sad" , color="black", alpha = 0.7, fontface="bold") + 
  annotate("text", x = 0.1, y = 0.95, 
           label = "Angry" , color="black", alpha = 0.7, fontface="bold") +
  annotate("text", x = 0.9, y = 0.05, 
           label = "Calm" , color="black",alpha = 0.7, fontface="bold") + 
  annotate("text", x = 0.9, y = 0.95, 
           label = "Happy" , color="black", alpha = 0.7, fontface="bold") +
  ggtitle("The mood of the songs in the different wrapped playlists") +
    geom_hline(yintercept=0.5, linetype="dashed", color = "orange") +
  geom_vline(xintercept = 0.5, linetype="dashed", 
                color = "orange")

scatterplotyears
```


***

The overall pattern, especially between 2019 and 2020, is similar. The songs are quite equally spread over the categories sad, angry and happy with the least songs in the category calm. 

This is already an interesting find that there are not much calm songs in my Wrapped playlists, although I even have a separate playlist called 'calm' where I listen to all the time. Maybe my perception of calm songs is different than that of spotify. 

The wrapped playlist of 2018 has more songs in the categories angry and happy. As stated in the introduction some songs in this playlist I have not listened to myself, but spotify selected them. It could be that spotify tends to add more angry and happy songs to a wrapped playlist, but further research is neccesary to find out if this is true and what the reason for it could be. 


### In depth visualisation of the influence of **Billie Eilish**

#### Comparing the mood of Billie Eilish with the mood of playlist wrapped 2019

```{r, fig.width=9, warning=FALSE}
scatterplotbillie <- billie %>%
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
      label = track.name
    )
  ) +
  geom_point(size = 1.5, color = '#008ae6', alpha = 0.6) +              # Scatter plot.   
  
  facet_wrap(~category) +     # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  labs(
    x = "Valence",
    y = "Energy",
    color = element_blank()
  ) +
  
  theme_light() +             # Use a simpler theme.
  
  theme( 
  strip.background = element_rect(fill="#008ae6", size=1.5, linetype="solid"), 
  legend.key = element_rect(fill = "#e7e7e4")
) + 
  annotate("text", x = 0.1, y = 0.05, 
           label = "Sad" , color="black", alpha = 0.7, fontface="bold") + 
  annotate("text", x = 0.1, y = 0.95, 
           label = "Angry" , color="black", alpha = 0.7, fontface="bold") +
  annotate("text", x = 0.9, y = 0.05, 
           label = "Calm" , color="black",alpha = 0.7, fontface="bold") + 
  annotate("text", x = 0.9, y = 0.95, 
           label = "Happy" , color="black", alpha = 0.7, fontface="bold") +
  geom_hline(yintercept=0.5, linetype="dashed", color = "orange") +
  geom_vline(xintercept = 0.5, linetype="dashed", 
                color = "orange")

ggplotly(scatterplotbillie)

```

*** 

I also want to see how much the influence of Billie Eilish is on the wrapped playlist of 2019 because 20 numbers are from her in this list. As expected most of her songs fall under the category 'sad'. Because she had a significant amount of numbers in the 2019 wrapped playlist, this can also account for the more low energy songs in this playlist relative to 2020 and 2018. 

This graph is interactive so when hovering over the points, the valence, energy and trackname of each individual song appears. 

### What about the **tempo** of the songs, does it differ over the years? 

```{r, fig.width=8}
hist_tempo <- combined %>%
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 10, col="black", fill = "#0088cc") +
    geom_density() +
  facet_wrap(~category) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme_light() +
  theme( 
  axis.text = element_text(size = rel(0.95)), 
  strip.background = element_rect(fill="#008ae6", size=1.5, linetype="solid"),
  strip.text = element_text(size = 12),
    plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
) +
    labs(                      
    x = "Tempo",
    y = "Number of songs",
    colour = element_blank()
  ) +
    ggtitle("The tempo of the songs") 

density_tempo <- ggplot(combined, aes(x=tempo, fill = category)) +
  geom_density(alpha = 0.4) +
    scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme_light() +
      labs(                      
    x = "Tempo",
    y = "Density",
    fill = element_blank()
  ) +
  theme(
    plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  )+
geom_vline(xintercept = 116, linetype="dotted", 
                color = "black", size=1.5) +
   geom_text(aes(x=130, label="\nmean tempo", y=0.020), colour="black", text=element_text(size=10)) +
    ggtitle("The density of songs filtered by tempo over the years") 

grid.arrange(hist_tempo, density_tempo, nrow=2)
```

***

For comparing the feature tempo between the three wrapped playlists, I created three histograms, one for each year, with a corresponding density plot of the three histograms combined. 

Looking at these graphs one can conclude that the wrapped playlists are similar in their tempo. The density plots for the three years overlap almost completly. Wrapped 2019 just has a slight preference for lower tempo songs where the density is the highest. This corresponds with the previous finding of Wrapped 2019 having the lowest energy songs. 

The mean tempo of the three wrapped playlists is 117 beats per minute (BPM). This is close to the preferred tempo of 120 BPM proposed by the article of Moelants published in 2002 [1]. My mean preferred tempo of songs is thus the same as the one they are proposing as the natural preferred tempo. 

*[1] Moelants, Dirk. 2002. ‘Preferred Tempo Reconsidered.’ In Proceedings of the 7th International Conference on Music Perception and Cognition, pp. 580–83. Adelaide, Australia*


### Let's go more in depth into the corpus songs and look at their **keys**

```{r, fig.width=9}
bar_combined <- combined %>%
  ggplot(aes(x = key_name)) +
  geom_bar(stat="count", aes(fill = category), alpha = 0.9, position = "dodge") +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme_light() +
  theme( 
  legend.title = element_blank(),
  axis.text = element_text(size = rel(0.95)), 
  strip.background = element_rect(fill="#008ae6", size=1.5, linetype="solid"),
  strip.text = element_text(size = 12),
  plot.title = element_text(size=12, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
) +
    labs(                      
    x = "Key",
    y = "Number of songs",
    colour = element_blank()
  ) +
    ggtitle("Key distribution in the Wrapped playlists") 

bar_combined 
```      

***

Left is a histogram with for every key shown how many songs in each wrapped playlist are played in that key. 

The most common key in the corpus is for all the three playlists C and the least common key D#. 

2019 and 2020 have for some keys the exact same number of songs in that key and other keys similar number of songs in it. 2018 has a more different distribution of keys and once again just like in the mood comparison graphic wrapped playlist 2018 is a bit of an outlier out of the three playlists. 

### **1.1 Chromagram**: The most calm song out of all the different playlists: *Fica tudo bem*

```{r}
fica <-
  get_tidy_audio_analysis("0trB3R0YBk3vGrGm5YSUTv") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

```

```{r, fig.width=8}
fica %>%
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(option = "cividis") + theme(plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  ) +
  ggtitle("Chromagram Fica tudo bem")

```

***

The chromagram of 'Fica Tudo Bem' looks very regular with the time intervals being the same between the different notes played. Maybe this causes the song to sound extra calm. The most used keys are: C, D#/Eb and F. To have a comparison point for this chromagram, on the next storyboard a chromagram of the most angry song is made. 


### **1.2 Chromagram**: The most angry song out of the playlists chromogram: *Like I do*

```{r}
ido <-
  get_tidy_audio_analysis("6RnkFd8Fqqgk1Uni8RgqCQ") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```

```{r, fig.width=8}
ido %>%
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(option = "cividis") +
  theme(
        plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  )+
  ggtitle("Chromagram Like I do")
```

***
The chromogram of 'Like I do' looks a lot less regular than the one of the most calm song. The notes have different magnitude ranges at different time intervals. For example the first 50 seconds D#/Eb is played frequently then 50 seconds not anymore and after 100 seconds it comes back again in magnitude. The most used keys are: C, G#/Ab and G.

In both outliers C is the most used keys, which also came back as the most common key in general for songs in the corpus. 

### **2.1** Further discussion of the **chroma and timbre features** of the outliers in the corpus: *Pastempomat*

```{r, fig.width=6}
polen <-
  get_tidy_audio_analysis("5hYQAKnuCccdHmp0zCjLlE") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  polen %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  polen %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none", option = "cividis") +
  theme_classic() +
  labs(x = "seconds", y = "") +
  theme(
    strip.text = element_text(size = 14),
        plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  ) +
  ggtitle('Self-Similarity matrices Pastempomat')

```


*** 

Pastempomat was one of the songs in the 2018 wrapped playlist that I did not listen to before. That is why I want to look at the details of the song to try to understand why spotify has put the song in my wrapped 2018 playlist. 

The chroma- and timbre-based self-similarity matrices show a clear structure in the song. The segments represent the bars of the song. In the chroma-based SSM especially a lot of paths are visible. In the song you can hear this as certain order of cords being repeated after each other. The first 10 seconds sound the same as the 10 seconds that follow thereafter. In the timbre-based SSM this shows a block-like structure for the first 20 seconds because of the homogeneous harmony in the sound. 

Both SSM show a bright vertical yellow line around 125 seconds. This is the start of the bridge where the background music stops and you just hear the singer sing. Another point where the background music stops is around 145 seconds which is again shown by bright vertical line in the timbre-based SSM but not in the chroma-based SSM. 


### **2.2** Further discussion of the **chroma and timbre features** of the outliers in the corpus: *Fica tudo bem*

```{r, fig.width=6}

Fica <-
  get_tidy_audio_analysis("0trB3R0YBk3vGrGm5YSUTv") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  Fica %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  Fica %>%
    compmus_self_similarity(timbre, "cosine") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none", option = "cividis") +
  theme_classic() +
  labs(x = "", y = "")+
  theme(
    strip.text = element_text(size = 14),
        plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  ) +
  ggtitle('Self-Similarity matrices Fica tudo bem')

```

***

Just like the chromagram was very regular in structure for Fica tudo bem, the chroma-based self-similarity matrix is too. It consist of a lot of small block-like structure. The timbre-based SSM has some more differences in structure. Here bigger block-like structure is seen where the harmony of the song is homogeneous. 

The parts where just instrumental music is played are clearly seen around 50 to 65 seconds and in the last part of the song after 130 seconds. The refrain is being played twice which is seen by the two darker blocks from 35 to 50 seconds and from 95 to 110 seconds. 


### **3.1** How well can spotify analyse the **tonality** of the outliers of the corpus?: *Fica tudo bem*

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

```
```{r}
tudo <-
  get_tidy_audio_analysis("0trB3R0YBk3vGrGm5YSUTv") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
tudo %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "angular",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "cividis") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  theme(
    plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  )+
  ggtitle("Keygram Fica tudo bem")
```

***

On the left you can see another analysis of the most calm song out of the corpus: Fica tudo bem. The song is divided into sections and for each section Spotify estimated the key. The key is estimated by computing the distance of the Spotify chroma vectors to the Krumhansl-Kessler key profiles. 

As one can see right away is that the key estimates are very blurry. A clear key estimate would show one key having a dark blue color block and the others a more brighter for example yellow color. In this key gram a lot of keys have a darker blue color and thus it is not clear how the tonality in the song changes. 

A final observation in the keygram are the vertical yellow parts, first one being seen between 50 and 65 seconds. In the song these sections are the parts where just instrumentals are playing and where the key-finding algorithm has the most trouble finding an estimate for the key of that section. 


### **3.2** How well can spotify analyse the **tonality** of the outliers of the corpus?: *Like I do*

```{r}
like <-
  get_tidy_audio_analysis("6RnkFd8Fqqgk1Uni8RgqCQ") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

```

```{r}
like %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "angular",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "cividis") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  theme(
    plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  )+
  ggtitle("Keygram Like I do")
```

*** 

On the left you can see another analysis of the most angry song out of the corpus: Like I do. Just like for the song: Fica tudo bem, this song is divided into sections and for each section Spotify estimated the key. The key is estimated by computing the distance of the Spotify chroma vectors to the Krumhansl-Kessler key profiles. 

A slighty better estimate of keys is made in this keygram compared to the previous one. It is clear that the song starts out in the key C minor. And around 130 to 140 seconds the key is a Ab major or a F minor. Looking back at the chromagram of Like I do one could also see a bigger magnitude for the Ab pitch around this time in the song compared to the other pitches. 

But for most of the song the key estimates are very blurry and not clear. Especially in the refrain parts of the song at around 45-95s and 145-190s. 

After looking at the two keygrams it can be concluded that Spotify has trouble analysing the tonality of the outliers in my corpus. 


### Coming back to the general corpus and see if a **classifier** can be trained on it?  

```{r, fig.width=9}
plot <- combined_knn %>% get_conf_mat() %>% autoplot(type = "mosaic") + scale_colour_brewer(
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  theme(
    plot.title = element_text(size=14, 
    margin = margin(10, 0, 10, 0), hjust = 0.5)
  ) +
  ggtitle('Confusion matrix corpus')

plot
```

***

For my corpus I investigated if a classifier could be trained with Spotify features to distinguish between my three wrapped playlists. First a random-forest classifier was used to see which features were most important in classifying tracks.

This gave the following features list:

  - loudness
  - duration
  - energy 
  - Timbre component 2, 3, 4 en 11

On the left the mosaic plot of the confusion matrix shows the results, after 10-fold cross-validation of a k = 1 nearest neighbour classifier trained with the features list. 
The classifier does not perform that well. It’s accuracy is below the 50 percent. The precision of the classifier’s predictions of wrapped playlist 2020 is the lowest with just 28 percent. The classifier is more likely to predict tracks of wrapped playlist 2020 as wrapped playlist 2018 than of actually part of wrapped playlist 2020.  

Conclusion: Just looking at the Spotify features list provided above is not enough to get a well performing classifier to distinguish between my wrapped Spotify playlists. A reason for this could be that my playlists are very similar and that is why the classifier has trouble distinguishing between them or that we need different features to make the distinction.

### Afther the research, what can be **concluded** about the three Wrapped playlists? 

The goal of this research was to find out how the type of music I listened too has evolved over the last three years. Different Spotify features were used for answering the question and the overall results are shown in the table below. 

|Energy  | Mood | Tempo | Keys | Outliers|
| ------ | ---- | ----- | ---- | --------|
| 2019 had the lowest overall energy in comparison to 2018 and 2020. With 2018 having the most high energy songs. | All of the three playlists did not have many 'calm' songs. The other songs were equally distributed across 'angry', 'happy' and 'sad'. With 2018 having a slight preference for 'happy' and 'angry'. | Tempo was very similar between the three playlists with 2019 having a slight preference for lower tempo songs. | The three playlists had the same most common and least common key. And 2019 and 2020 were very similar looking at the key of their songs. | The most calm and most angry song do show differences, but more outliers need to be investigated to analyse a real pattern. |

Conclusion: The tree wrapped playlist have stayed pretty similiar over the last three years. It depends on the Spotify feature you are focusing on which of the three playlists are the most similar to each other. The extra research question: can you tell from the wrapped playlist what my overall mood was for that year? had contradictionary results compared to my expectations beforehand. 2019 was overall the playlist with the most 'sad', low energy and low tempo songs, while I expected the opposite. 

The result of this research has given me inside about which music I tend to be listening to the most over the years. I have a broad interest in different music styles and you could see in the results that not one mood category, tempo, key, or energy level was over represented in my corpus. This broad range of results can cause the similarity between the three playlists because I do not have one specific music style with specific set of Spotify features. Also I found out that if I have a more fun and energetic year I listen to more 'sad' low energy songs. The results of 2019 however could have been affected with the large influence of the 20 Billie Eilish songs. Tracking my wrapped playlist for the years to come will give more insights in my music type and when i listen to which kind of music. 